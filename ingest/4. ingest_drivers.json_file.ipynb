{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b744eb6-a77e-49ec-a656-c0a92e290c09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read in json data using spark df reader\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3401e030-9cdf-4136-b97d-1c6d3f85f1f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema\n",
    "name_schema = StructType(fields=[StructField(\"forename\", StringType(), True),\n",
    "                                 StructField(\"surname\", StringType(), True)\n",
    "  \n",
    "])\n",
    "\n",
    "drivers_schema = StructType(fields=[StructField(\"driverId\", IntegerType(), False),\n",
    "                                    StructField(\"driverRef\", StringType(), True),\n",
    "                                    StructField(\"number\", IntegerType(), True),\n",
    "                                    StructField(\"code\", StringType(), True),\n",
    "                                    StructField(\"name\", name_schema),\n",
    "                                    StructField(\"dob\", DateType(), True),\n",
    "                                    StructField(\"nationality\", StringType(), True),\n",
    "                                    StructField(\"url\", StringType(), True)  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b4e0de-ff34-4e25-82e8-36dcd47cd0f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read data into df\n",
    "drivers_df = spark.read \\\n",
    ".schema(drivers_schema) \\\n",
    ".json(\"/mnt/jdoformula1dl/raw/drivers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1d945c-1530-4138-a985-4a19beab0b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rename columns for better clarity and add new columns - ingestion date \n",
    "from pyspark.sql.functions import current_timestamp, col, concat, lit\n",
    "drivers_with_columns_df = drivers_df.withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    "                                    .withColumnRenamed(\"driverRef\", \"driver_ref\") \\\n",
    "                                    .withColumn(\"ingestion_date\", current_timestamp()) \\\n",
    "                                    .withColumn(\"name\", concat(col(\"name.forename\"), lit(\" \"), col(\"name.surname\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245f02e9-801f-4132-8f30-52f5005f4731",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop unwanted columns\n",
    "drivers_final_df = drivers_with_columns_df.drop(col(\"url\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8147e244-e8f4-4364-a945-f5261317c284",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write output as parquet to processed container\n",
    "drivers_final_df.write.mode(\"overwrite\").parquet(\"/mnt/jdoformula1dl/processed/drivers\")    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4. ingest_drivers.json_file",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
