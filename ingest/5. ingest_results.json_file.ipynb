{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a727441e-cab5-41d6-8357-fb62fff3403c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the json file using spark df reader\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "# Define schema\n",
    "results_schema = StructType(fields=[StructField(\"resultId\", IntegerType(), False),\n",
    "                                    StructField(\"raceId\", IntegerType(), True),\n",
    "                                    StructField(\"driverId\", IntegerType(), True),\n",
    "                                    StructField(\"constructorId\", IntegerType(), True),\n",
    "                                    StructField(\"number\", IntegerType(), True),\n",
    "                                    StructField(\"grid\", IntegerType(), True),\n",
    "                                    StructField(\"position\", IntegerType(), True),\n",
    "                                    StructField(\"positionText\", StringType(), True),\n",
    "                                    StructField(\"positionOrder\", IntegerType(), True),\n",
    "                                    StructField(\"points\", FloatType(), True),\n",
    "                                    StructField(\"laps\", IntegerType(), True),\n",
    "                                    StructField(\"time\", StringType(), True),\n",
    "                                    StructField(\"milliseconds\", IntegerType(), True),\n",
    "                                    StructField(\"fastestLap\", IntegerType(), True),\n",
    "                                    StructField(\"rank\", IntegerType(), True),\n",
    "                                    StructField(\"fastestLapTime\", StringType(), True),\n",
    "                                    StructField(\"fastestLapSpeed\", FloatType(), True),\n",
    "                                    StructField(\"statusId\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c969e25-9c68-4cc3-a1e9-b0ec745b7751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read data in df\n",
    "results_df = spark.read.schema(results_schema).json(\"/mnt/jdoformula1dl/raw/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a557f3-0045-4e56-a2bd-0a045145304b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rename columns and add ingestion date column]\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "results_with_columns_df = results_df.withColumnRenamed(\"resultId\", \"result_id\") \\\n",
    "                                    .withColumnRenamed(\"raceId\", \"race_id\") \\\n",
    "                                    .withColumnRenamed(\"driverId\", \"driver_id\") \\\n",
    "                                    .withColumnRenamed(\"constructorId\", \"constructor_id\") \\\n",
    "                                    .withColumnRenamed(\"positionText\", \"position_text\") \\\n",
    "                                    .withColumnRenamed(\"positionOrder\", \"position_order\") \\\n",
    "                                    .withColumnRenamed(\"fastestLap\", \"fastest_lap\") \\\n",
    "                                    .withColumnRenamed(\"fastestLapTime\", \"fastest_lap_time\") \\\n",
    "                                    .withColumnRenamed(\"fastestLapSpeed\", \"fastest_lap_speed\") \\\n",
    "                                    .withColumn(\"ingestion_date\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5620b2f2-9175-4ce4-861a-7462b6a9e15e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop unwanted column\n",
    "from pyspark.sql.functions import col\n",
    "results_final_df = results_with_columns_df.drop(col(\"statusId\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d60ae6af-bf19-45af-8165-a9bab1fdc453",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write parquet file to processed container\n",
    "results_final_df.write.mode(\"overwrite\").parquet(\"/mnt/jdoformula1dl/processed/results\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "5. ingest_results.json_file",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
